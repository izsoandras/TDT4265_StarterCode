# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G6-8yCkFNJwAvyC-oNb0Z3AYyGI376kl
"""

import torchvision
import pathlib
import matplotlib.pyplot as plt
from matplotlib.offsetbox import AnchoredText
import torch.nn

import utils
from torch import nn
from dataloaders import load_cifar10
from trainer import Trainer
from trainer import compute_loss_and_accuracy


import numpy as np

import torch
import typing
import time
import collections
import utils
import pathlib


def compute_loss_and_accuracy(
        dataloader: torch.utils.data.DataLoader,
        model: torch.nn.Module,
        loss_criterion: torch.nn.modules.loss._Loss):
    """
    Computes the average loss and the accuracy over the whole dataset
    in dataloader.
    Args:
        dataloder: Validation/Test dataloader
        model: torch.nn.Module
        loss_criterion: The loss criterion, e.g: torch.nn.CrossEntropyLoss()
    Returns:
        [average_loss, accuracy]: both scalar.
    """
    average_loss = 0
    accuracy = 0
    # TODO: Implement this function (Task  2a)
    n = len(dataloader.dataset)
    with torch.no_grad():
        batches = 0
        for (X_batch, Y_batch) in dataloader:
            batches += 1
            # Transfer images/labels to GPU VRAM, if possible
            X_batch = utils.to_cuda(X_batch)
            Y_batch = utils.to_cuda(Y_batch)
            # Forward pass the images through our model
            output_probs = model(X_batch)

            # Compute Loss and Accuracy
            average_loss += loss_criterion(output_probs, Y_batch)
            corr_predictions = 0
            for i in range(X_batch.shape[0]):
                output_probs[i, :] = (output_probs[i, :] == max(output_probs[i, :])) * 1
                corr_predictions += output_probs[i, Y_batch[i]] == 1
            print(corr_predictions)
            accuracy += corr_predictions / Y_batch.shape[0]
    return average_loss / batches, accuracy / batches


class Trainer:

    def __init__(self,
                 batch_size: int,
                 learning_rate: float,
                 early_stop_count: int,
                 epochs: int,
                 model: torch.nn.Module,
                 dataloaders: typing.List[torch.utils.data.DataLoader]):
        """
            Initialize our trainer class.
        """
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.early_stop_count = early_stop_count
        self.epochs = epochs

        # Since we are doing multi-class classification, we use CrossEntropyLoss
        self.loss_criterion = torch.nn.CrossEntropyLoss()
        # Initialize the model
        self.model = model
        # Transfer model to GPU VRAM, if possible.
        self.model = utils.to_cuda(self.model)
        print(self.model)

        # Define our optimizer. SGD = Stochastich Gradient Descent
        # self.optimizer = torch.optim.SGD(self.model.parameters(),
        #                                  self.learning_rate)
        self.optimizer = torch.optim.Adam(self.model.parameters(),
                                         self.learning_rate)

        # Load our dataset
        self.dataloader_train, self.dataloader_val, self.dataloader_test = dataloaders

        # Validate our model everytime we pass through 50% of the dataset
        self.num_steps_per_val = len(self.dataloader_train) // 2
        self.global_step = 0
        self.start_time = time.time()

        # Tracking variables
        self.train_history = dict(
            loss=collections.OrderedDict(),
            accuracy=collections.OrderedDict()

        )
        self.validation_history = dict(
            loss=collections.OrderedDict(),
            accuracy=collections.OrderedDict()
        )
        self.test_history = dict(
            loss=collections.OrderedDict(),
            accuracy=collections.OrderedDict()
        )
        self.checkpoint_dir = pathlib.Path("checkpoints")

    def validation_step(self):
        """
            Computes the loss/accuracy for all three datasets.
            Train, validation and test.
        """
        self.model.eval()
        validation_loss, validation_acc = compute_loss_and_accuracy(
            self.dataloader_val, self.model, self.loss_criterion
        )
        self.validation_history["loss"][self.global_step] = validation_loss
        self.validation_history["accuracy"][self.global_step] = validation_acc

        test_loss, test_acc = compute_loss_and_accuracy(
            self.dataloader_test, self.model, self.loss_criterion
        )
        self.test_history["loss"][self.global_step] = test_loss
        self.test_history["accuracy"][self.global_step] = test_acc
        used_time = time.time() - self.start_time

        print(
            f"Epoch: {self.epoch:>1}",
            f"Batches per seconds: {self.global_step / used_time:.2f}",
            f"Global step: {self.global_step:>6}",
            f"Validation Loss: {validation_loss:.2f}",
            f"Validation Accuracy: {validation_acc:.3f}",
            sep=", ")
        self.model.train()

    def should_early_stop(self):
        """
            Checks if validation loss doesn't improve over early_stop_count epochs.
        """
        # Check if we have more than early_stop_count elements in our validation_loss list.
        val_loss = self.validation_history["loss"]
        if len(val_loss) < self.early_stop_count:
            return False
        # We only care about the last [early_stop_count] losses.
        relevant_loss = list(val_loss.values())[-self.early_stop_count:]
        first_loss = relevant_loss[0]
        if first_loss == min(relevant_loss):
            print("Early stop criteria met")
            return True
        return False

    def train_step(self, X_batch, Y_batch):
        """
        Perform forward, backward and gradient descent step here.
        The function is called once for every batch (see trainer.py) to perform the train step.
        The function returns the mean loss value which is then automatically logged in our variable self.train_history.

        Args:
            X: one batch of images
            Y: one batch of labels
        Returns:
            loss value (float) on batch
        """
        # X_batch is the CIFAR10 images. Shape: [batch_size, 3, 32, 32]
        # Y_batch is the CIFAR10 image label. Shape: [batch_size]
        # Transfer images / labels to GPU VRAM, if possible
        X_batch = utils.to_cuda(X_batch)
        Y_batch = utils.to_cuda(Y_batch)

        # Perform the forward pass
        predictions = self.model(X_batch)
        # Compute the cross entropy loss for the batch
        loss = self.loss_criterion(predictions, Y_batch)
        # Backpropagation
        loss.backward()
        # Gradient descent step
        self.optimizer.step()
        # Reset all computed gradients to 0
        self.optimizer.zero_grad()

        return loss.detach().cpu().item()

    def train(self):
        """
        Trains the model for [self.epochs] epochs.
        """
        def should_validate_model():
            return self.global_step % self.num_steps_per_val == 0

        for epoch in range(self.epochs):
            self.epoch = epoch
            # Perform a full pass through all the training samples
            for X_batch, Y_batch in self.dataloader_train:
                loss = self.train_step(X_batch, Y_batch)
                self.train_history["loss"][self.global_step] = loss
                self.global_step += 1
                # Compute loss/accuracy for validation set
                if should_validate_model():
                    self.validation_step()
                    self.save_model()
                    if self.should_early_stop():
                        print("Early stopping.")
                        return

    def save_model(self):
        def is_best_model():
            """
                Returns True if current model has the lowest validation loss
            """
            val_loss = self.validation_history["loss"]
            validation_losses = list(val_loss.values())
            return validation_losses[-1] == min(validation_losses)

        state_dict = self.model.state_dict()
        filepath = self.checkpoint_dir.joinpath(f"{self.global_step}.ckpt")

        utils.save_checkpoint(state_dict, filepath, is_best_model())

    def load_best_model(self):
        state_dict = utils.load_best_checkpoint(self.checkpoint_dir)
        if state_dict is None:
            print(
                f"Could not load best checkpoint. Did not find under: {self.checkpoint_dir}")
            return
        self.model.load_state_dict(state_dict)

class Model(nn.Module):
  def __init__(self):
    super().__init__()
    self.model = torchvision.models.resnet18(pretrained=True)
    self.model.fc = nn.Linear(512, 10) # No need to apply softmax,
    # as this is done in nn.CrossEntropyLoss
    for param in self.model.parameters(): # Freeze all parameters
      param.requires_grad = False
    for param in self.model.fc.parameters(): # Unfreeze the last fully-connected
      param.requires_grad = True # layer
    for param in self.model.layer4.parameters(): # Unfreeze the last 5 convolutional
      param.requires_grad = True # layers

  def forward(self, x):
    x = self.model(x)
    return x

utils.set_seed(0)
epochs = 10
batch_size = 32
learning_rate = 5e-4
early_stop_count = 4
dataloaders = load_cifar10(batch_size)
model = Model()
trainer = Trainer(
    batch_size,
    learning_rate,
    early_stop_count,
    epochs,
    model,
    dataloaders
)
trainer.train()

print(trainer.test_history['accuracy'])

from typing_extensions import OrderedDict

model_name = "dropout"
train_history = {
    "accuracy": OrderedDict(),
    "loss":OrderedDict()
}
validation_history = {
    "accuracy": OrderedDict(),
    "loss":OrderedDict()
}
test_history = {
    "accuracy": OrderedDict(),
    "loss":OrderedDict()
}

for hs in zip([train_history,validation_history, test_history],[trainer.train_history, trainer.validation_history, trainer.test_history]):
  for k1 in hs[1].keys():
    for k2 in hs[1][k1].keys():
      if type(hs[1][k1][k2]) is not float:
        hs[0][k1][k2] = hs[1][k1][k2].cpu().numpy()

# train_history["loss"] = trainer.train_history["loss"]
# validation_history["loss"] = [t.cpu().numpy() for t in trainer.validation_history["loss"].values()]
# test_history["loss"] = [t.cpu().numpy() for t in trainer.test_history["loss"].values()]
# train_history["accuracy"] = [t.cpu().numpy() for t in trainer.train_history["accuracy"].values()]
# validation_history["accuracy"] = [t.cpu().numpy() for t in trainer.validation_history["accuracy"].values()]
# test_history["accuracy"] = [t.cpu().numpy() for t in trainer.test_history["accuracy"].values()]

np.save(f"history/model_{model_name}_train.npy", train_history)
np.save(f"history/model_{model_name}_val.npy", validation_history)
np.save(f"history/model_{model_name}_test.npy", test_history)

model_name = "dropout"
train_history = np.load(f"history/model_{model_name}_train.npy", allow_pickle=True)[()]
validation_history = np.load(f"history/model_{model_name}_val.npy", allow_pickle=True)[()]
test_history = np.load(f"history/model_{model_name}_test.npy", allow_pickle=True)[()]


plot_path = pathlib.Path("plots")
plot_path.mkdir(exist_ok=True)
# Save plots and show them
plt.figure(figsize=(20, 8))
plt.subplot(1, 2, 1)
plt.title("Cross Entropy Loss")
utils.plot_loss(train_history["loss"], label="Training loss", npoints_to_average=10)
utils.plot_loss(validation_history["loss"], label="Validation loss")
utils.plot_loss(test_history["loss"], label="Test loss")
plt.legend()
plt.subplot(1, 2, 2)
plt.title("Accuracy")
utils.plot_loss(validation_history["accuracy"], label="Validation Accuracy")
utils.plot_loss(test_history["accuracy"], label="Test Accuracy")
plt.legend()
# # these are matplotlib.patch.Patch properties
# props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)
# # place a text box in upper left in axes coords
# plt.text(0.05, 0.95, f"Final accuracy:\nTrain: {trainer.train_history['accuracy']}%\nValidation: {trainer.validation_history['accuracy']}%\nTest: {trainer.test_history['accuracy']}%", fontsize=14,
#         verticalalignment='top', bbox=props)


# text_box = AnchoredText(f"Final accuracy:\nTrain: {list(train_history['accuracy'].values())[-1]}%\nValidation: {list(validation_history['accuracy'].values())[-1]}%\nTest: {list(test_history['accuracy'].values())[-1]}%", frameon=True, loc=4, pad=0.5)
text_box = AnchoredText(f"Final accuracy:\nValidation: {list(validation_history['accuracy'].values())[-1]*100:.2f}%\nTest: {list(test_history['accuracy'].values())[-1]*100:.2f}%", frameon=True, loc=4, pad=0.5)
plt.setp(text_box.patch, facecolor='white', alpha=0.5)
plt.gca().add_artist(text_box)

plt.savefig(plot_path.joinpath(f"4a.png"))

plt.show()
print(list(validation_history["accuracy"].values())[-1])
print(list(test_history["accuracy"].values())[-1])

import matplotlib.pyplot as plt
from PIL import Image
import torchvision
import torch
import numpy as np
image = Image.open("zebra.jpg")
print("Image shape:", image.size)

model = torchvision.models.resnet18(pretrained=True)
# print(model)
first_conv_layer = model.conv1
print("First conv layer weight shape:", first_conv_layer.weight.shape)
print("First conv layer:", first_conv_layer)

# Resize, and normalize the image with the mean and standard deviation
image_transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize((224, 224)),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
image = image_transform(image)[None]
print("Image shape:", image.shape)

activation = first_conv_layer(image)
print("Activation shape:", activation.shape)


def torch_image_to_numpy(image: torch.Tensor):
    """
    Function to transform a pytorch tensor to numpy image
    Args:
        image: shape=[3, height, width]
    Returns:
        iamge: shape=[height, width, 3] in the range [0, 1]
    """
    # Normalize to [0 - 1.0]
    image = image.detach().cpu() # Transform image to CPU memory (if on GPU VRAM)
    image = image - image.min()
    image = image / image.max()
    image = image.numpy()
    if len(image.shape) == 2: # Grayscale image, can just return
        return image
    assert image.shape[0] == 3, "Expected color channel to be on first axis. Got: {}".format(image.shape)
    image = np.moveaxis(image, 0, 2)
    return image


indices = [14, 26, 32, 49, 52]

pics = []
for i in indices:
  pics.append( torch_image_to_numpy(activation[0,i]))


plt.figure()
for idx, pic in enumerate(pics):
  plt.subplot(2,5,idx+1)
  # plt.imshow(pic)
  plt.imshow(np.transpose(first_conv_layer.weight[idx].detach().numpy()))
  plt.subplot(2,5,5+idx+1)
  plt.imshow(pic)

plt.savefig('plots/4b.png')

layers = list(model.children())

res = image
layer = model.children()
for l in range(0,len(layers)-2):
  res = layers[l](res)

plt.figure()
for i in range(0,10):
  plt.subplot(2,5,i+1)
  plt.imshow(res[0,i].detach().numpy())

plt.savefig('plots/4c.png')